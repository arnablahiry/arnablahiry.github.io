<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Research</title>
    <link rel="stylesheet" href="css/utils.css">
    <link rel="stylesheet" href="css/research_style.css">
    <link rel="stylesheet" href="css/light_mode.css">
    <link rel="stylesheet" href="css/research_light_mode.css">
    <!-- Math rendering: MathJax for this page (also enabled site-wide in header include) -->
    <script>
        window.MathJax = window.MathJax || {
            tex: { inlineMath: [['$','$'], ['\\(','\\)']], displayMath: [['$$','$$'], ['\\[','\\]']] },
            options: { skipHtmlTags: ['script','noscript','style','textarea','pre'] }
        };
    </script>
    <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" async></script>
    <script src="scripts/latex.js"></script>
</head>
<body>

    <header>
        <div class="logo-container">
            <a href="index.html" aria-label="Home">
                <img src="images/logo.png" alt="Logo" class="logo">
        <script>/* early theme apply */(function(){try{var t=localStorage.getItem('site:theme'); if(t==='light') document.documentElement.classList.add('light-mode');}catch(e){} })();</script>
            </a>
        </div>
        <button class="hamburger" aria-label="Open menu" aria-controls="site-nav" aria-expanded="false">
            <span class="bar bar1"></span>
            <span class="bar bar2"></span>
            <span class="bar bar3"></span>
        </button>
        <nav id="site-nav">
            <a href="index.html">Home</a>
            <a href="about.html">About</a>
            <a href="timeline.html">Timeline</a>
            <a href="research.html">Research</a>
            <a href="publications.html">Publications</a>
            <a href="repositories.html">Repositories</a>
            <a href="contact.html">Contact</a>
            <button id="theme-toggle" class="theme-toggle" aria-pressed="false" aria-label="Toggle light/dark mode">☀</button>
        </nav>
    </header>

    <div class="page-wrapper">
        <div class="section-timeline-heading">
            <div class="container">
                <div class="padding-vertical-xlarge">
                    <div class="timeline-main-heading-wrapper">
                        <!-- Theme toggle moved to the navbar for site-wide placement -->
                            <div class="margin-bottom-medium">
                            <h2 class="intro-heading">My Scientific <span class="break-after">Research</span></h2>
                        </div>
                        <div class="margin-bottom-medium research-heading-row">
                            <div class="research-intro-text">
                                <p class="research-intro">I work at the intersection of machine learning and astrophysical research. I design end‑to‑end AI workflows - from data curation and denoising to model design, training, and deployment - with a strong emphasis on interpretability, reproducibility, and physically informed methods. My focus is on building robust, production‑ready ML/AI tools that bridge computer‑science practice and scientific research so models provide reliable, testable scientific insight rather than black‑box predictions.</p>
                            </div>

                            <!-- Meme placed to the right of the intro text; height will match the text column -->
                            <div class="research-meme">
                                <div class="meme-wrapper" id="meme-wrapper">
                                    <img src="images/research/meme.png" alt="Research meme" class="timeline-hero-image" loading="lazy" id="meme-image">
                                    <div class="meme-overlay" id="meme-overlay">
                                        <button class="reveal-btn" id="reveal-btn" aria-label="Reveal image">Reveal meme ;)</button>
                                    </div>
                                </div>
                            </div>
                        </div>
                        <!-- Optional subtitle or hero image could go here -->
                    </div>
                </div>
            </div>
        </div>

        <div class="section-timeline">
            <div class="container">
                <!-- Projects grid: each card has an image + subtitle; clicking expands details -->
                <div class="projects-grid" id="projects-grid">
                    <article class="project-card">
                        <img class="project-image" src="images/research/galprop.svg" alt="Project image">
                        <div class="project-meta">
                            <h3 class="project-title">Beyond Moment0: Galaxy Property Inference</h3>
                            <p class="project-subtitle">Using simulated mock IFUs to use the full emission spectrum per-pixel to infer physical galaxy properties.</p>
                        </div>
                        <button class="project-toggle" aria-expanded="false" aria-controls="proj-1-desc">Learn more</button>
                        <div class="project-full" hidden>
                            <h4>Overview</h4>
                            <p>This project builds end-to-end AI workflows for scientific datasets. It includes data preprocessing and augmentation, denoising stages, model architecture search, uncertainty quantification, and a deployment-ready pipeline that includes validation, monitoring and reproducibility tooling.</p>
                            <h4>Highlights</h4>
                            <ul>
                                <li>Interpretable model outputs and diagnostic visualisations</li>
                                <li>Automated training pipelines with reproducible experiments</li>
                                <li>Integration with evaluation suites and uncertainty estimators</li>
                            </ul>
                        </div>
                    </article>

                    <article class="project-card">
                        <img class="project-image" src="images/research/3d_denoising.svg" alt="Project image">
                        <div class="project-meta">
                            <h3 class="project-title">Deep and Sparse Denoising of high-z Galaxy Spectral Cubes</h3>
                            <p class="project-subtitle">Tiered three-dimensional de-noising comparitive study - toy data, simulations and ALMA observations.</p>
                        </div>
                        <button class="project-toggle" aria-expanded="false" aria-controls="proj-2-desc">Learn more</button>
        
                        <div class="project-full" hidden>
                            <p>We embed physically motivated constraints and preprocessing into model training to ensure learned representations respect domain structure. The work focuses on diagnostic tools that reveal why models behave a certain way and how predictions relate to known physics.</p>
                        </div>
                    </article>

                    <article class="project-card">
                        <img class="project-image" src="images/research/cnn_cosmo.svg" alt="Project image">
                        <div class="project-meta">
                            <h3 class="project-title">CNN and Simulation-based Cosmological Interpretability</h3>
                            <p class="project-subtitle">Exploring the scales and morphology of the cosmic web to interpret the origin of cosmological information.</p>
                        </div>
                        <button class="project-toggle" aria-expanded="false" aria-controls="proj-3-desc">Learn more</button>
                        <div class="project-full" hidden>

                            <p><strong>Overview:</strong></p>
                            <p>
                                This project investigates the interpretability of Convolutional Neural Networks (CNNs) applied to field-level cosmological inference. Utilizing the <strong>CAMELS</strong> (Cosmology and Astrophysics with MachinE Learning Simulations) dataset, specifically the IllustrisTNG suite, this work explores how neural networks extract cosmological parameters ($\Omega_m$ and $\sigma_8$) from total matter density fields in the presence of complex baryonic physics. The study focuses on identifying which morphological features of the cosmic web—such as voids, filaments, or halos—drive the network's predictions.
                            </p>

                            <figure style="text-align: center; margin: 20px 0;">
                                <img src="images/research/cnn_interpret.svg" alt="Visualization of Cosmic Web Attribution" style="max-width: 80%; height: auto;">
                                <figcaption>Fig 1. Visualization of cosmic web attribution for neural network interpretability.</figcaption>
                            </figure>

                            <h3>Methodology</h3>
                            <p>
                                The analysis pipeline consists of three primary stages:
                            </p>
                            <ul>
                                <li><strong>Simulation-Based Inference:</strong> A CNN is trained to map 2D total matter density fields ($X$) to the posterior distributions of cosmological parameters ($\theta$), predicting both the mean and variance.</li>
                                <li><strong>Attribution Mapping:</strong> Post-training, interpretability algorithms (Saliency Maps, Integrated Gradients, and GradientSHAP) are applied to quantify the contribution of individual pixels to the model's inference.</li>
                                <li><strong>Information Cutting:</strong> The robustness of the model is tested by systematically removing information via Fourier scale cuts ($k_{max}$) and density threshold cuts ($\rho_{min}, \rho_{max}$).</li>
                            </ul>

                            <h3>Key Mathematical Framework</h3>
                            <p>
                                The neural network predicts the mean ($\mu_i$) and variance ($\sigma_i^2$) of the marginal posterior for the $i$-th parameter:
                            </p>
                            
                            $$ \mu_{i}(X)=\int_{\theta_{i}}p(\theta_{i}|X)\theta_{i}d\theta_{i} $$
                            $$ \sigma_{i}^{2}(X)=\int_{\theta_{i}}p(\theta_{i}|X)(\theta_{i}-\mu_{i})^{2}d\theta_{i} $$

                            <p>
                                To optimize these predictions, the model minimizes a custom loss function designed for moment matching:
                            </p>

                            $$
                            \begin{aligned}
                            \mathcal{L} &= \sum_{i=1}^{6}\log\left(\sum_{j\in \mathrm{batch}}(\theta_{i,j}-\mu_{i,j})^{2}\right) \\
                            &\quad+ \sum_{i=1}^{6}\log\left(\sum_{j\in \mathrm{batch}}\big( (\theta_{i,j}-\mu_{i,j})^{2}-\sigma_{i,j}^{2} \big)^{2}\right)
                            \end{aligned}
                            $$

                            <p>
                                To interpret <em>how</em> the model learns, the <strong>Integrated Gradients (IG)</strong> method was chosen for its mathematical robustness. IG calculates the path integral of the gradients from a baseline input $x'$ (noise) to the actual input $x$:
                            </p>

                            $$ IG_{i}(x)=(x_{i}-x_{i}^{\prime})\int_{0}^{1}\frac{\partial f(x^{\prime}+\alpha(x-x^{\prime}))}{\partial x_{i}}d\alpha $$

                            <h3>Key Results & Insights</h3>
                            <ul>
                                <li><strong>Morphological Focus:</strong> Attribution maps reveal that CNNs extract cosmological information from both high-density regions (halos) and low-density regions (voids). While overdense regions provide the most "information per pixel," underdense regions contribute significantly due to their large spatial extent and coherent features.</li>
                                <li><strong>Robustness to Scale Cuts:</strong> The model demonstrates remarkable robustness to Fourier scale cuts. There is negligible degradation in cosmological constraining power even after removing small scales (cutting at $k_{max} \sim 20~h/Mpc$), suggesting the network can marginalize over uncertain baryonic effects that dominate small scales.</li>
                                <li><strong>Baryonic Independence:</strong> Experiments comparing full hydrodynamic simulations to gravity-only (N-body) simulations yielded similar results for $\Omega_m$, implying the neural network effectively learns the underlying dark matter morphology regardless of baryonic feedback mechanisms.</li>
                                <li><strong>The Power of Voids:</strong> Density cut analysis showed that even when high-density halos are removed, the network retains significant accuracy by relying on the structures within voids and filaments.</li>
                            </ul>
                        </div>
                    </article>
                </div>
            </div>
        </div>
    </div>

    <footer>
        <p>&copy; 2025 Arnab Lahiry</p>
    </footer>

    <script src="scripts/nav-toggle.js"></script>
    <script src="scripts/research.js"></script>
    <script src="scripts/reveal-meme.js"></script>
    <script src="scripts/theme-toggle.js"></script>
</body>
</html>
